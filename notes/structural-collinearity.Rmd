---
title: "Structural Collinearity"
author: "Andrew Zieffler"
date: "11/3/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Preparation

```{r}
library(corrr)
library(car)

library(tidyverse)
library(patchwork)

bluegills = read_csv("../data/bluegills.csv")
head(bluegills)
```


## Structural Collinearity

Let's imagine that we adopted a cubic polynomial model to predict variation in fish length. This model includes three predictors: the linear, quadratic, and cubic effects of age. The correlation matrix of these predictors suggests that the two predictors are highly correlated. (This is not surprising given that we created the quadratic and cubic terms from the linear term.)

<aside>
Note that we need to create the polynomial terms in the data to examine the correlation matrix.
</aside>

```{r}
bluegills %>%
  mutate(
    age_quad  = age ^ 2,
    age_cubic = age ^ 3
  ) %>%
  select(length, age, age_quad, age_cubic) %>%
  correlate()
```

If we look at the VIF indices associated with the coefficients from the quadratic model, we find that the sampling variances for the coefficients are grossly inflated. When we have collinearity that is a result of the structural form of the model (e.g., polynomials, interactions), we refer to it as *structural multicollinearity*.

```{r}
lm.3 = lm(length ~ 1 + age + I(age^2) + I(age^3), data = bluegills)
vif(lm.3)

# Effect on SEs
sqrt(vif(lm.3))
```

To alleviate this, we can center the age predictor and use the centered age to create the polynomial terms.

```{r}
bluegills = bluegills %>%
  mutate(
    c_age = as.numeric(scale(age, center = TRUE, scale = FALSE)),
    c_age2 = c_age ^ 2,
    c_age3 = c_age ^ 3
  )
```

The new correlation matrix using the predictors based on centered age show much smaller correlations between the predictors.

```{r}
bluegills %>%
  select(length, c_age, c_age2, c_age3) %>%
  correlate()
```


The model based on the polynomials created from the centered age shows much better VIF indices.

```{r}
lm.3_c = lm(length ~ 1 + c_age + I(c_age^2) + I(c_age^3), data = bluegills)
vif(lm.3_c)

# Effect on SEs
sqrt(vif(lm.3_c))
```


While the coefficients for the polynomials based on the centered age are different (they should be), the fitted model produces the same plot (just shifted to the left; centered).

```{r}
coef(lm.3_c)
```


```{r eval = FALSE}
data.frame(
  c_age = seq(from = -2.63, to = 2.37, by = 0.01) #Set up sequence of x-values
  ) %>%
  mutate(
    yhat = predict(lm.3_c, newdata = .) #Get y-hat values based on model
  ) %>%
  ggplot(aes(x = c_age, y = yhat)) +
    geom_line() +
    theme_bw() +
    xlab("Centered Age") +
    ylab("Predicted length")
```

```{r echo=FALSE, fig.width = 8, fig.height = 4}
p1 = data.frame(
  c_age = seq(from = -2.63, to = 2.37, by = 0.01) #Set up sequence of x-values
  ) %>%
  mutate(
    yhat = predict(lm.3_c, newdata = .) #Get y-hat values based on model
  ) %>%
  ggplot(aes(x = c_age, y = yhat)) +
    geom_point() +
    geom_line() +
    theme_bw() +
    xlab("Centered Age") +
    ylab("Predicted length") +
    ggtitle("Centered Age")

p2 = data.frame(
  age = seq(from = 1, to = 6, by = 0.1) #Set up sequence of x-values
  ) %>%
  mutate(
    yhat = predict(lm.3, newdata = .) #Get y-hat values based on model
  ) %>%
  ggplot(aes(x = age, y = yhat)) +
    geom_point() +
    geom_line() +
    theme_bw() +
    xlab("Age") +
    ylab("Predicted length") +
    ggtitle("Raw Age")

p1 | p2
```

### Orthogonal Polynomials

Another way to deal with the structural multicollinearity is to use *orthogonal polynomial contrasts*. In the design matrix for the polynomials based on the raw age values, each row is composed of $[1,x,x^2]$, where $x$ is age. Othogonal contrasts are a particular way of generating the design matrix so that the columns are linearly independent. To create these we use the `poly()` function with the argument `raw=FALSE` (or omit the `raw=` argument all together). Below are the first several rows of the design matrix for the: (1) polynomials based on raw age; (2) polynomials based on centered age; and (3) polynomials based on orthogonal contrasts.

```{r}
# Polynomials based on raw age
lm.2 = lm(length ~ 1 + poly(age, 3, raw = TRUE), data = bluegills)
head(model.matrix(lm.2))

# Polynomials based on centered age
lm.2_center = lm(length ~ 1 + poly(c_age, 3, raw = TRUE), data = bluegills)
head(model.matrix(lm.2_center))

# Polynomials based on orthogonal contrasts
lm.2_ortho = lm(length ~ 1 + poly(age, 3), data = bluegills)
head(model.matrix(lm.2_ortho))

```

Similar to the centered values, the orthogonal polynomials produce different estimates of the coefficients and SEs, but the *p*-values for the highest order polynomial term and the interpretations from the plot of the resulting fitted model will be identical to that of the model created from the raw ages.

<aside>
Because of the unchanged inferences for the highest order term and the equivalent model interpretations, while dealing with structural multicollinearity can be convenient in some cases, it is not essential.
</aside>



## References
