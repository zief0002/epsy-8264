---
title: "Regression Splines I"
author: "Andrew Zieffler"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output: 
  html_document:
    highlight: zenburn
    css: ['style/style.css', 'style/table-styles.css', 'style/syntax.css', 'style/notes.css']
bibliography: epsy8264.bib
csl: 'style/apa-single-spaced.csl'
---

<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, 
  fig.width = 6, 
  fig.height = 6, 
  fig.align = 'center',
  out.width = "40%", 
  message = FALSE, 
  warning = FALSE
  )
```

**These notes draw from @Berk:2016.**

<br />



```{r message=FALSE}
# Load libraries
library(broom)
library(educate)
library(patchwork)
library(tidyverse)
```

In the last set of notes we fitted a continuous linear piecewise model to the Tokyo water data. There is nothing that limits the degree of the piecewise model fitted to be degree one (linear). We could fit a higher order polynomial model to each region of the data as well. For example, below, we fit not only the linear piecewise model, but also the quadratic and cubic piecewise models to a toy data set. In each of these fits, we used knots $k_1=4$ and $k_2=7$.

```{r echo=FALSE, fig.align='center', fig.width=12, fig.height=4, out.width='90%', fig.cap="Plot of the fitted values from a continuous linear (LEFT), quadratic (MIDDLE), and cubic (RIGHT) piecewise models for the fake data. Knots were included at x={4, 7}."}
fake = read_csv("../data/fake-piecewise-data.csv")

fake = fake %>%
  mutate(
    S_1 = if_else(x <= 4, 0, x - 4),
    S_2 = if_else(x <= 7, 0, x - 7)
  )

# Fit linear piecewise model
lm.pw.1 = lm(y ~ 1 + x +                   S_1 +                       S_2,                       data = fake)
lm.pw.2 = lm(y ~ 1 + x + I(x^2) +          S_1 + I(S_1^2) +            S_2 + I(S_2^2),            data = fake)
lm.pw.3 = lm(y ~ 1 + x + I(x^2) + I(x^3) + S_1 + I(S_1^2) + I(S_1^3) + S_2 + I(S_2^2) + I(S_2^3), data = fake)


# Create data set for plot
plot_data = data.frame(
  x = seq(from = 0, to = 10, by = 0.1)
) %>%
  mutate(
    S_1 = if_else(x <= 4, 0, x - 4),
    S_2 = if_else(x <= 7, 0, x - 7)
  )

# Add in fitted values
plot_data = plot_data %>%
  mutate(
    yhat1 = predict(lm.pw.1, newdata = plot_data),
    yhat2 = predict(lm.pw.2, newdata = plot_data),
    yhat3 = predict(lm.pw.3, newdata = plot_data)
  ) %>%
  tidyr::gather(model, yhat, yhat1:yhat3) %>%
  mutate(
    model = factor(model, levels = c("yhat1", "yhat2", "yhat3"), labels = c("Linear", "Quadratic", "Cubic"))
  )


ggplot(data = plot_data, aes(x = x, y = yhat)) +
  geom_vline(xintercept = c(4, 7), linetype = "dotted") +
  geom_point(data = fake, aes(x = x, y = y), alpha = 0.5) +
  geom_line() +
  theme_light() +
  scale_x_continuous(name = "X", breaks = seq(from = 0, to = 10, by = 2)) +
  scale_y_continuous(
    name = "Y", 
    breaks = seq(from = -1.5, to = 3, by = 0.5)
  ) +
  theme(
    panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank()
  ) +
  facet_wrap(~model)
```

The plot of the fitted models are show: 

- **Linear Piecewise Model:** A linear model has been fitted to each of the three regions of the data with the constraint that the fitted models for two adjacent regions intersect at the knot.
- **Quadratic Piecewise Model:** A quadratic polynomial model has been fitted to each of the three regions of the data with the constraint that the fitted models for two adjacent regions intersect at the knot.
- **Cubic Piecewise Model:** A cubic polynomial model has been fitted to each of the three regions of the data with the constraint that the fitted models for two adjacent regions intersect at the knot.


## Tokyo Water Example: Quadratic Piecewise Model

The data in *tokyo-water-use.csv* were collected due to concerns about the provision of potable water to large metropolitan areas, which is a potential problem resulting from human-induced climate change. The data consist of 27 years worth of residential water use (measured in 1000s of cubic feet). We previously fitted a linear piecewise model to the data based on knots we defined at 1980 and 1992, and constrained these piecewise models to be continous at the knots. Below we fit both the continous linear and quadratic piecewise models.

```{r message=FALSE}
# Import data
tokyo = read_csv("../data/tokyo-water-use.csv")


# Create indicators
tokyo = tokyo %>%
  mutate(
    S_1 = if_else(year <= 1980, 0, year - 1980),
    S_2 = if_else(year <= 1992, 0, year - 1992)
  )


# Fit linear piecewise model
lm.pw.1 = lm(water_use ~ 1 + year + S_1 + S_2, data = tokyo)


# Fit quadratic piecewise model
lm.pw.2 = lm(water_use ~ 1 + year + I(year^2) + S_1 + I(S_1^2) + S_2 + I(S_2^2), data = tokyo)
```

The plot of the fitted models are shown below. Note that in the quadratic piecewise model a quadratic model has been fitted to each of the three regions of the data. Again, these models have been constrained to be continuous so that they intersect at the knots.

```{r fig.width=8, fig.height=4, out.width='90%', fig.align='center', fig.cap="Plot of the fitted values from a continuous linear (LEFT) and quadratic (RIGHT) piecewise model for the Tokyo water use data. Knots were included at 1980 amd 1992."}
# Create data set for plot
plot_data = data.frame(
  year = seq(from = 1973, to = 1999, by = 0.1)
) %>%
  mutate(
    S_1 = if_else(year <= 1980, 0, year - 1980),
    S_2 = if_else(year <= 1992, 0, year - 1992)
  )

# Add in fitted values
plot_data = plot_data %>%
  mutate(
    yhat1 = predict(lm.pw.1, newdata = plot_data),
    yhat2 = predict(lm.pw.2, newdata = plot_data)
  ) %>%
  tidyr::gather(model, yhat, yhat1:yhat2) %>%
  mutate(
    model = factor(model, levels = c("yhat1", "yhat2"), labels = c("Linear", "Quadratic"))
  )


# Plot
ggplot(data = plot_data, aes(x = year, y = yhat)) +
  geom_line() +
  geom_point(data = tokyo, aes(x = year, y = water_use), alpha = 0.5) +
  theme_light() +
  scale_x_continuous(name = "Year", breaks = seq(from = 1970, to = 2005, by = 5)) +
  scale_y_continuous(
    name = "Residential water use (in 1000 cubic feet)", 
    breaks = seq(from = 600000, to = 740000, by = 20000)
    ) +
  facet_wrap(~model)
```

To evaluate these two models, we will examine the residuals from both models.  

```{r echo=FALSE, fig.width=8, fig.height=8, out.width='90%', fig.align='center', fig.cap="Residual plots for the linear (top row) and quadratic (bottom row) continuous piecewise models fitted to the Tokyo water use data using knots at 1980 and 1992."}
# Augment the model
out_pw_1 = augment(lm.pw.1)
out_pw_2 = augment(lm.pw.2)

# Evaluate residuals

# Density plot of residuals (linear model)
p1 = ggplot(data = out_pw_1, aes(x = .std.resid)) +
  stat_density_confidence(model = "normal") +
  stat_density(geom = "line") +
  theme_light() +
  labs(
    x = "Standardized residuals",
    y = "Probability density",
    title = "Linear Model"
  )

# Residuals versus fitted values (linear model)
p2 = ggplot(data = out_pw_1, aes(x = .fitted, y = .std.resid)) +
  geom_point()  +
  geom_smooth() +
  geom_hline(yintercept = 0) +
  theme_light() +
  labs(
    x = "Fitted values",
    y = "Standardized residuals",
    title = "Linear Model"
  )

# Density plot of residuals (quadratic model)
p3 = ggplot(data = out_pw_2, aes(x = .std.resid)) +
  stat_density_confidence(model = "normal") +
  stat_density(geom = "line") +
  theme_light() +
  labs(
    x = "Standardized residuals",
    y = "Probability density",
    title = "Quadratic Model"
  )

# Residuals versus fitted values (quadratic model)
p4 = ggplot(data= out_pw_2, aes(x = .fitted, y = .std.resid)) +
  geom_point()  +
  geom_smooth() +
  geom_hline(yintercept = 0) +
  theme_light()  +
  labs(
    x = "Fitted values",
    y = "Standardized residuals",
    title = "Quadratic Model"
  )

# Layout plots
(p1 | p2) / (p3 | p4)
```

Based on these plots, it appears that the quadratic piecewise model has better fit to the data. While the empirical evidence indicates that there may be problems with the normality assumption, the more important assumption that the average residual is 0 looks far better for the quadratic piecewise model. 

Adopting this model suggests that over time, residential water usage is non-linear within each of the local data regions. Prior to 1980 there is rapid increase in water use followed by rapid decrease. From 1980 to 1992, residential water use grows at an ever increasing (non-linear) rate until 1992 at which time water use decreases non-linearly until about 1996. Since then, water use seems to be increasing.

<br />

## Spline Models

Although the continuous piecewise quadratic model indicates better residual fit, one problem with it is that the points at which the piecewise models intersect at the knots are quite unnatural; there are abrupt changes in the relationship between time and water use at these points. This is simply a function of the continuity constraint that we added to the model. To alleviate these abrupt changes at the knots we impose two additional constraints:

- The first derivative of the piecewise functions be continuous at the knots; and
- The second derivative of the piecewise functions be continuous at the knots.

These constraints will impose not only continuity of the function at the knots, but will also impose *smoothness* of the function at the knots. The piecewise polynomial models having these additional smoothing constraints are referred to as *spline models*. To illustrate this, we fit a set of cubic piecewise models to the same toy dataset we saw earlier. The first cubic model (a) has no constraints, the second cubic model (b) has the constraint of continuity in $f(x)$, and the third cubic model, a cubic spline (c), has the the constraints of continuity in $f(x)$, $f^{\prime}(x)$, and $f^{\prime\prime}(x)$. We also fit a global cubic polynomial model for comparison.


```{r echo=FALSE, fig.width=12, fig.height=8, out.width='90%', fig.cap="Plot of four fitted cubic models to the fake data having different constraints. TOP: The global cubic model. BOTTOM LEFT: This piecewise model imposes no constraints. BOTTOM MIDDLE: This piecewise model imposes continuity in f(x). BOTTOM RIGHT: This piecewise model imposes continuity in f(x), the first derivative of f(x), and the second derivative of f(x)."}
library(splines)

fake = fake %>%
  mutate(
    S_1 = if_else(x <= 4, 0, x - 4),
    S_2 = if_else(x <= 7, 0, x - 7)
  )

# Fit cubic piecewise model
lm.pw.3 = lm(y ~ 1 + x + I(x^2) + I(x^3) + S_1 + I(S_1^2) + I(S_1^3) + S_2 + I(S_2^2) + I(S_2^3), data = fake)

# Cubic spline model
spline.3 = lm(y ~ bs(x, knots = c(4, 7), degree = 3), data = fake)

# Create data set for pw model
plot_data = data.frame(
  x = seq(from = 0, to = 10, by = 0.1)
) %>%
  mutate(
    S_1 = if_else(x <= 4, 0, x - 4),
    S_2 = if_else(x <= 7, 0, x - 7)
  ) %>%
  mutate(yhat = predict(lm.pw.3, newdata = .))

# Create data set for spline model
plot_data2 = data.frame(
  x = seq(from = 0, to = 10, by = 0.1)
  ) %>%
  mutate(yhat = predict(spline.3, newdata = .))

p0 = ggplot(data = fake, aes(x = x, y = y)) +
  geom_vline(xintercept = c(4, 7), linetype = "dotted") +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", se = FALSE, formula = y~poly(x, 3), color = "black") +
  theme_light() +
  scale_x_continuous(name = "X", breaks = seq(from = 0, to = 10, by = 2)) +
  scale_y_continuous(
    name = "Y",
    breaks = seq(from = -1.5, to = 3, by = 0.5)
  ) +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank()
  ) +
  ggtitle("Global Cubic Polynomial")

p1 = ggplot(data = fake, aes(x = x, y = y)) +
  geom_vline(xintercept = c(4, 7), linetype = "dotted") +
  geom_point(alpha = 0.5) +
  geom_smooth(data = fake[fake$x <= 4, ], method = "lm", se = FALSE, formula = y~poly(x, 3), color = "black") +
  geom_smooth(data = fake[fake$x > 4 & fake$x <= 7, ], method = "lm", se = FALSE, formula = y~poly(x, 3), color = "black") +
  geom_smooth(data = fake[fake$x > 7, ], method = "lm", se = FALSE, formula = y~poly(x, 3), color = "black") +
  theme_light() +
  scale_x_continuous(name = "X", breaks = seq(from = 0, to = 10, by = 2)) +
  scale_y_continuous(
    name = "Y",
    breaks = seq(from = -1.5, to = 3, by = 0.5)
  ) +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank()
  ) +
  ggtitle("No Constraints")

p2 = ggplot(data = plot_data, aes(x = x, y = yhat)) +
  geom_vline(xintercept = c(4, 7), linetype = "dotted") +
  geom_point(data = fake, aes(x = x, y = y), alpha = 0.5) +
  geom_line() +
  theme_light() +
  scale_x_continuous(name = "X", breaks = seq(from = 0, to = 10, by = 2)) +
  scale_y_continuous(
    name = "Y",
    breaks = seq(from = -1.5, to = 3, by = 0.5)
  ) +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank()
  )  +
  ggtitle("Continuous on f(x)")

p3 = ggplot(data = plot_data2, aes(x = x, y = yhat)) +
  geom_vline(xintercept = c(4, 7), linetype = "dotted") +
  geom_point(data = fake, aes(x = x, y = y), alpha = 0.5) +
  geom_line() +
  theme_light() +
  scale_x_continuous(name = "X", breaks = seq(from = 0, to = 10, by = 2)) +
  scale_y_continuous(
    name = "Y",
    breaks = seq(from = -1.5, to = 3, by = 0.5)
  ) +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank()
  )  +
  ggtitle("Continuous on f(x), f'(x), and f''(x)")

# Layout plots
(plot_spacer() | p0 | plot_spacer()) / (p1 | p2 | p3)
```

The four models suggest different relationships between *x* and *y*. For example, the global cubic polynomial shows rapid increase in *y* up to, about, $x=6$, followed by slight decrease in *y*. The piecewise models suggest quite a different global trend to the data. In general all three piecewise models indicate a negative rate of change until $x=1.5$ followed by rapid increase in *y* until $x=5$. Then this function decreases until $x=9$ and then shows rapid increase. 

While the global trends in the piecewise models are similar, the discontinuous and continuous cubic piecewise model shows more variation in the trend at each locale than the spline model. The additional continuity constraints of the cubic spline model (BOTTOM RIGHT) "smooth" out this local variation, often making it a more attractive model. 


<br />

### Model Complexity and Continuity Constraints

Interestingly, aside smoothing out the transitions from one locality to the next, imposing continuity constraints on the model reduces the model complexity; more continuity constraints are associated with smaller model *df*. In general, each continuity constraint free up a degree of freedom in the model. Using our three fitted models:

- The "no constraints" model has an intercept, linear, quadratic, and cubic term that needs to be estimated in each of the three regions. This means that the model will use up 12 *df*. 
- The second model imposed that the function, f(x), was continuous at each of the two knots. Therefore, this frees up 2 degrees of freedom, which means this model uses up $12 - 2 = 10$ *df*. 
- The cubic spline model imposed continuity constraints at each knot on $f(x)$, $f^{\prime}(x)$, and $f^{\prime\prime}(x)$. This frees up 6 *df*, so this model uses $12 - 6 = 6$ *df*.

<br />

### General Definition of a Spline

For the cubic spline (degree = 3), we imposed continuity constraints on $f(x)$, $f^{\prime}(x)$, and $f^{\prime\prime}(x)$. In other words, to fit a degree *d* spline model, we impose continuity constraints on the function and all derivatives up to $f^{d-1}(x)$. For example, for the quadratic spline (degree = 2) we impose continuity constraints on $f(x)$ and $f^{\prime}(x)$. For a linear spline, we only impose continuity on $f(x)$. (Terminology note: This means that all continuous piecewise models are spline models.)

How do we fit a degree *d* piecewise model so that is function and the derivatives of its function up to the $d-1$th derivative are continuous? According to @James:2013, in order to fit a degree *d* spline model we include the polynomial predictors of *x* up to (and including) $x^d$ using an **orthogonal basis function** (e.g., `poly()`). Then we also include an indicator predictor for each knot that is:

$$
S_k = \begin{cases}
    0 & x \leq k \\
    (x-k)^d & x > k
\end{cases}
$$

By including this indicator, the function and all derivatives up to the $d$th derivative will be continuous at each knot. For example, in our Tokyo data, to fit a cubic spline model with knots at 1980 and 1992, we would fit the following model:

$$
\mathrm{Water~Use}_i = \beta_0 + \beta_1\bigg(b(\mathrm{Year}_i)\bigg) + \beta_2\bigg(b(\mathrm{Year}_i^2)\bigg) + \beta_3\bigg(b(\mathrm{Year}_i^3)\bigg) + \beta_4(S_{1i}) + \beta_5(S_{2i}) + \epsilon_i
$$

where,

$b(.)$ is an orthogonal basis function applied to $x$,

$$
S_{1_i} = \begin{cases}
    0 & \mathrm{Year}_i \leq 1980 \\
    (\mathrm{Year}_i-1980)^3 & \mathrm{Year}_i > 1980
\end{cases}
$$

and

$$
S_{2_i} = \begin{cases}
    0 & \mathrm{Year}_i \leq 1992 \\
    (\mathrm{Year}_i-1992)^3 & \mathrm{Year}_i > 1992
\end{cases}
$$
<br />

#### Digression: Orthogonal Basis Function

The `poly()` function uses an orthogonal basis to create a set of corresponding values that can be used in the `lm()` function in place of the original data to produce the same set of predicted values. These corresponding values are orthogonal to one another, and to the intercept which reduces structural collinearity. 

For example, consider the predictor, *X*, which consistes of $X = \{1,2,3,4,5\}$. We will also create a $Y$ from these values that has a cubic structure.

```{r}
# Create example data
x = 1:5
y = 2 - x + 0.3*x^2 - 1.4*x^3 + rnorm(n = 5, mean = 0, sd = 0.4)
```

If we create the design matrix to fit a cubic polynomial using the raw data values, we get:

$$
\mathbf{X} = \begin{bmatrix}
  1 & 1 & 1 & 1\\
  1 & 2 & 4 & 8\\
  1 & 3 & 9 & 27\\
  1 & 4 & 16 & 64\\
  1 & 5 & 25 & 125\\
  \end{bmatrix}
$$

Looking at the correlations between the columns of this matrix, we find that the intercorrelations between the polynomial terms are quite large. Moreover, the eigenvalues from the $\mathbf{X}^{\intercal}\mathbf{X}$ suggest that collinearity will be a problem.

```{r}
# Create design matrix
X = cbind(rep(1, 5), x, x^2, x^3)
X

# Compute correlations
cor(X)

# Compute eigenvalues from X'X matrix
eigen(t(X) %*% X)
```

What if we convert the design matrix to an orthogonal basis using the `poly()` function? Now the design matrix is:

$$
\mathbf{X} = \begin{bmatrix}
  1 &  -0.632 &  0.535 & -0.316\\
  1 &  -0.316 & -0.267 &  0.632\\
  1 &   0.000 & -0.535 &  0.000\\
  1 &   0.316 & -0.267 & -0.632\\
  1 &   0.632 &  0.535 &  0.316\\
  \end{bmatrix}
$$

The intercorrelations between these column vectors are all essentially 0 and the eigenvalues do not suggest a collinearity problem. By changing the basis we can remove structural collinearity issues.

```{r}
# Create design matrix
X_poly = cbind(rep(1, 5), poly(x, 3))
X_poly

# Compute correlations
cor(X_poly)

# Compute eigenvalues from X'X matrix
eigen(t(X_poly) %*% X_poly)
```

What does this change when we compare the models?

```{r}
# Fit model
lm.raw = lm(y ~ 1 + x + I(x^2) + I(x^3))

# Fit orthogonal polynomial basis model
lm.poly = lm(y ~ 1 + poly(x, 3))
```

At the coefficient-level, the output is quite different. This is because the basis changed. This means the interpretation of the coefficients also changes. In a regression context, the interpretation around the coefficients from the orthogonal polynomial basis are nonsensical---they no longer represent an interaction effect since the effects of the polynomials are independent in this basis. If we are interested in understanding the polynomial effect at the coefficient-level, we should be using the original basis.

```{r}
# Coefficient-level output for raw basis
tidy(lm.raw)

# Coefficient-level output for orthogonal basis
tidy(lm.poly)
```


At the model-level, however, all of the output is identical. This is because the predicted values from the two equations are identical.

```{r}
# Model-level output for raw basis
print(glance(lm.raw), width = Inf)

# Model-level output for orthogonal basis
print(glance(lm.poly), width = Inf)
```

In the spline model, we don't care about the actual coefficients, only the predicted values from the model (to create our plot). In this case, the orthogonal basis is preferred because we need it to satisfy the requirements of fitting the spline model.

<br />

#### Back to Spline Models


After creating the indicator variables, we can estimate the coefficients using OLS estimation.


```{r}
# Create indicators
tokyo = tokyo %>%
  mutate(
    S_1 = if_else(year <= 1980, 0, (year - 1980)^3),
    S_2 = if_else(year <= 1992, 0, (year - 1992)^3)
  )

# Fit spline model
lm.spline.3 = lm(water_use ~ 1 + poly(year, 3) + S_1 + S_2, data = tokyo)

# Model-level output
print(glance(lm.spline.3),, width = Inf)
```

Based on the model-level output, we see that the model has 6 *df* (including the intercept). The coefficient-level output (not shown) is irrelevant to us except as a way of obtaining a plot of the fitted model.

```{r}
# Create plotting data
plot_data = data.frame(
  year = seq(from = 1973, to = 1999, by = 0.1)
  ) %>%
  mutate(
    S_1 = if_else(year <= 1980, 0, (year - 1980)^3),
    S_2 = if_else(year <= 1992, 0, (year - 1992)^3)
  ) %>%
  mutate(
    yhat = predict(lm.spline.3, newdata = .)
  )

# Plot
ggplot(data = plot_data, aes(x = year, y = yhat)) +
  geom_line() +
  geom_point(data = tokyo, aes(x = year, y = water_use), alpha = 0.5) +
  theme_light() +
  scale_x_continuous(name = "Year", breaks = seq(from = 1970, to = 2005, by = 5)) +
  scale_y_continuous(
    name = "Residential water use (in 1000 cubic feet)",
    breaks = seq(from = 600000, to = 740000, by = 20000)
  )
```

<br />

#### Fitting the Model with the Raw Polynomials

Since using the orthogonal polynomial basis and the raw polynomials should produce the same fitted values, does it matter which basis we choose? What would have happened had we fitted the model using the raw polynomials?

```{r}
# Fit the model using the raw polynomial basis
lm.spline.4 = lm(water_use ~ 1 + year + I(year^2) + I(year^3) + S_1 + S_2, data = tokyo)

# Model-level output
print(glance(lm.spline.4), width = Inf)
```
The model-level output is exactly the same as the cubic spline model we fitted earlier; changing the basis does not change the fit of the model. The problem comes in when we try to predict the model's fitted values to create our plot.

```{r warning=TRUE}
# Create plotting data
plot_data = data.frame(
  year = seq(from = 1973, to = 1999, by = 0.1)
  ) %>%
  mutate(
    S_1 = if_else(year <= 1980, 0, (year - 1980)^3),
    S_2 = if_else(year <= 1992, 0, (year - 1992)^3)
  ) %>%
  mutate(
    yhat = predict(lm.spline.4, newdata = .)
  )
```

The model cannot be used to create the fitted values because the model is rank-deficient (i.e., the columns are collinear). Using the orthogonal polynomial basis fixes this collinearity!

<br />

### Alternative Method for Fitting Spline Model

In practice, we rarely actually create the splines using polynomials and indicators as we just did. Instead, we typically use a B-spline basis for constructing splines, which, although result in the exact same fitted line, have better computational properties. The numerical detail underlying the B-spline basis is beyond the scope of this course, but interested readers can reference @Hastie:2009 for more detail.

To fit a cubic spline using the B-spline basis, we use the `bs()` function from the **splines** library. This function is applied directly to the predictor in the `lm()` function. There are several useful arguments for this function including: `knots=` to specify the knots, and `degree=` to indicate the degree of polynomial to use (the default is `degree=3`). By default, an intercept is not included in the B-spline basis (although this can be overridden by including `intercept=FALSE`) which is fine since all we care about is the plot of the fitted line, which is identical whether the intercept is included or not. Below we fit the cubic spline to the Tokyo data using the B-spline basis.

```{r}
# Load splines library
library(splines)

# Fit cubic spline using B-spline basis
bs.1 = lm(water_use ~ 1 + bs(year, knots = c(1980, 1992)), data = tokyo)

# Model-level output
print(glance(bs.1), width = Inf)
```

The model-level output is exactly the same as the cubic spline model we fitted earlier; changing the basis does not change the fit of the model. The coefficient-level output, however, is quite different:

```{r}
# Coefficient-level output
tidy(bs.1)
```


This is because we used a B-spline basis when we fitted this model. The basis essentially defines the design matrix used. In a B-spline basis, the design matrix is constituted by a set of indicator variables whose values are determined by the knots. Below we show the first ten rows for the design matrix for both spline models.

```{r}
# First 10 rows of design matrix for orthogonal polynomial basis
model.matrix(lm.spline.3)[1:10, ]

# First 10 rows of design matrix for raw polynomial basis
model.matrix(lm.spline.4)[1:10, ]

# First 10 rows of design matrix for B-spline basis
model.matrix(bs.1)[1:10, ]
```

Note that the B-spline basis used a set of five indicator variables. These represent five different regions of the data: the three regions defined by the two knots, and two additional boundary regions that extend beyond the data at either side. (Think about adding two additional knots, one beyond the data at each end. This results in five regions that need to be coded.) The main thing is that the two design matrices have the same dimensions, $27 \times 6$, and produce the same hat-matrix, which implies that they produce the same set of fitted values.

<br />

### Plotting the Fitted Model

To plot the fitted model, we will: 

- Create a data set that includes the values of the predictor we want to plot on the *x*-axis, in order from smallest to largest value;
- Add in the indicator variables;
- Compute the fitted values from these data;
- Use `geom_line()` to plot a line through each of the $(x,\hat{y})$ ordered pairs.


```{r}
# Set up data to plot
plot_data = data.frame(
  year = seq(from = 1973, to = 1999, by = 0.1)
) %>%
  mutate(
    yhat = predict(bs.1, newdata = .)
  )

# Plot
ggplot(data = plot_data, aes(x = year, y = yhat)) +
  geom_line() +
  geom_point(data = tokyo, aes(x = year, y = water_use), alpha = 0.5) +
  theme_light() +
  scale_x_continuous(name = "Year", breaks = seq(from = 1970, to = 2005, by = 5)) + 
  scale_y_continuous(
    name = "Residential water use (in 1000 cubic feet)",
    breaks = seq(from = 600000, to = 740000, by = 20000)
  )
```

When there are no covariates in the model, we can also plot the B-spline smoother directly using `geom_smooth()`, without creating the plotting data. To do this, we use `method="lm"` and change the `formula=` argument in the smoother. (The default argument is `formula=y~x`, which corresponds to the linear model.)

```{r}
# Plot
ggplot(data = plot_data, aes(x = year, y = yhat)) +
  geom_smooth(method = "lm", formula = y~bs(x, knots = c(1980, 1992)), color = "red") +
  geom_point(data = tokyo, aes(x = year, y = water_use), alpha = 0.5) +
  theme_light() +
  scale_x_continuous(name = "Year", breaks = seq(from = 1970, to = 2005, by = 5)) + 
  scale_y_continuous(
    name = "Residential water use (in 1000 cubic feet)",
    breaks = seq(from = 600000, to = 740000, by = 20000)
  )
```

If you have covariates, you need to set up the plotting data, obtain the fitted values, and then plot using `geom_line()`.




<br />

## References


