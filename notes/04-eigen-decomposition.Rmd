---
title: "Eigendecomposition (a.k.a., Spectrial Decomposition)"
description: |
  A brief introduction to eigendecomposition and some R syntax for carrying out eigendecomposition.
author:
  - name: Andrew Zieffler 
    url: https://zief0002.github.io/epsy-8264/
date: "`r Sys.Date()`"
output: 
  distill::distill_article:
    toc: true
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Eigendecomposition is a method of decomposing or factoring a matrix into a set of product matrices made up of *eigenvalues* and *eigenvectors*. Only square matrices that can be expressed as 

$$
\mathbf{A} = \mathbf{P}\mathbf{D}\mathbf{P}^{-1}
$$

where **D** is a diagonal matrix and **P** is an invertible matrix, can be eigendecomposed. If **A** can be expressed this way it is referred to as a *diagonalizable* matrix.


# Eigenvalues

An eigenvalue of matrix **A** is any non-zero scalar $\lambda$ such that, $\mathbf{A} - \lambda \mathbf{I}$ is singular (e.g., determinant is zero). Consider an example,

$$
\underset{n\times n}{\mathbf{A}} = \begin{bmatrix}
-3 & 5  \\ 
4 & -2  \\
\end{bmatrix}
$$
Our goal is to find the values of $\lambda$ that satisfy

$$
\mathrm{det}\bigg(\begin{bmatrix}
-3 & 5  \\ 
4 & -2  \\
\end{bmatrix} - \lambda\begin{bmatrix}
1 & 0  \\ 
0 & 1  \\
\end{bmatrix}\bigg) = 0
$$

Using matrix algebra,

$$
\begin{split}
\mathrm{det}\bigg(\begin{bmatrix}
-3 & 5  \\ 
4 & -2  \\
\end{bmatrix} - \lambda\begin{bmatrix}
1 & 0  \\ 
0 & 1  \\
\end{bmatrix}\bigg) &= 0 \\[1em]
\mathrm{det}\bigg(\begin{bmatrix}
-3 & 5  \\ 
4 & -2  \\
\end{bmatrix} - \begin{bmatrix}
\lambda & 0  \\ 
0 & \lambda  \\
\end{bmatrix}\bigg) &= 0 \\[1em]
\mathrm{det}\begin{bmatrix}
-3 - \lambda & 5  \\ 
4 & -2 - \lambda \\
\end{bmatrix} &= 0 \\[1em]
(-3 - \lambda)(-2 - \lambda) - 20 &= 0
\end{split}
$$

Computing the determinant, distributing the first set of terms (i.e., FOIL), subtracting 20 we obtain

$$
\begin{split}
(-3 - \lambda)(-2 - \lambda) - 20 &= 0 \\[1em]
6 + 3\lambda + 2\lambda + \lambda^2 -20 &= 0 \\[1em]
\lambda^2 + 5\lambda - 14 &= 0 \\[1em]
\end{split}
$$

Factoring the left-hand side, 

$$
(\lambda + 7)(\lambda - 2) = 0
$$

Solving for $\lambda$, we find that $\lambda = -7$ and $\lambda = 2$. We could also have applied the quadratic formula to solve this for $\lambda$.

<aside>
Remember the quadratic formula? The roots of the polynomial $Ax^2+Bx+C$ are computed using:

$$
x = \frac{-B\pm \sqrt{B^2-4AC}}{2A}
$$
Quick recap at [Khan Academy](https://www.khanacademy.org/math/algebra/x2f8bb11595b61c86:quadratic-functions-equations/x2f8bb11595b61c86:quadratic-formula-a1/v/using-the-quadratic-formula) if you need it.
</aside>

Now that we have the eigenvalues we can double-check that $\mathbf{A} - \lambda \mathbf{I}$ is singular. (I will skip this here, but plug in the values for $\lambda$, one at a time, and ensure that the determinant is zero.) The equation you solved,

$$
\mathrm{det}\big(\mathbf{A} - \lambda \mathbf{I}\big)=0
$$
is referred to as the *characteristic equation*. Solving the characteristic equation gives the eigenvalues. Sometimes the eigenvalues are referred to as the characteristic roots of matrix **A**.


# Eigenvectors

If $\lambda$ is an eigenvalue of matrix **A**, then it is possible to find a vector **v** (an eigenvector) that satisfies

$$
\mathbf{A}\mathbf{v} = \lambda \mathbf{v}
$$

Here since **A** is a $2\times2$ matrix, **v** will be a $2\times1$ vector to make the matrix multiplication work.

$$
\underset{2\times2}{\mathbf{A}}~\underset{2\times1}{\mathbf{v}} = \lambda \underset{2\times1}{\mathbf{v}}
$$
We can use matrix algebra to solve for the elements of vector **v** using each eigenvalue.


$$
\begin{split}
\mathbf{A}\mathbf{v} &= \lambda \mathbf{v} \\[1em]
\begin{bmatrix}
-3 & 5  \\ 
4 & -2  \\
\end{bmatrix}\begin{bmatrix}
v_1 \\ 
v_2 \\
\end{bmatrix} &= -7\begin{bmatrix}
v_1 \\ 
v_2 \\
\end{bmatrix}\\[1em]
\end{split}
$$

This produces a system of two equations with two unknowns:

$$
\begin{split}
-3v_1 + 5v_2 &= -7v_1 \\
4v_1 - 2v_2 &= -7v_2 
\end{split}
$$
Simplifying this, we get

$$
\begin{split}
4v_1 + 5v_2 &= 0 \\
4v_1 + 5v_2 &= 0 
\end{split}
$$
The homogeneous set of equations means that there are an infinite number of solutions. The general solution here is to express one variable (say $v_2$) as a function of the other.

$$
\begin{split}
v_1 &= \theta \\[0.5em]
v_2 &= -\frac{4}{5}\theta 
\end{split}
$$

Any set of $v_1$ and $v_2$ in which $v_2 = -\frac{4}{5}v_1$ will satisfy this set of equations. Although there are an infinite number of solutions, one that is particularly nice is that whose a sum of squared values is equal to 1.


$$
\begin{split}
v_1^2 + v_2^2 &= 1 \\[1em]
\theta^2 + (-\frac{4}{5}\theta)^2 &= 1 \\[1em]
\frac{41}{25}\theta^2 &= 1 \\[1em]
\theta^2 &= \frac{25}{41} \\[1em]
\theta &= \sqrt{\frac{25}{41}} \\[1em]
&=\frac{5}{\sqrt{41}}
\end{split}
$$
Which implies that,

$$
\begin{split}
v_1 &= \frac{5}{\sqrt{41}} \\[1em]
v_2 &= -\frac{4}{\sqrt{41}}
\end{split}
$$

And the eigenvector corresponding to the eigenvalue of $-7$ is

$$
\mathbf{v} = \begin{bmatrix}\frac{5}{\sqrt{41}} \\ -\frac{4}{\sqrt{41}}\end{bmatrix}
$$

We could verify this by ensuring that the the equation $\mathbf{A}\mathbf{v}=\lambda\mathbf{v}$ holds:

$$
\begin{bmatrix}
-3 & 5  \\ 
4 & -2  \\
\end{bmatrix}\begin{bmatrix}\frac{5}{\sqrt{41}} \\ -\frac{4}{\sqrt{41}}\end{bmatrix} = -7\begin{bmatrix}\frac{5}{\sqrt{41}} \\ -\frac{4}{\sqrt{41}}\end{bmatrix}
$$


We can follow the same process for the second eigenvector which corresponds to the eigenvalue of 2. This produces an eigenvector of 

$$
\mathbf{v} = \begin{bmatrix}\frac{1}{\sqrt{2}} \\ \frac{1}{\sqrt{2}}\end{bmatrix}
$$
Which can again be verified.


# Diagonalization

Let's place the two eigenvectors we found in a matrix **P**.

$$
\mathbf{P} = \begin{bmatrix}\frac{5}{\sqrt{41}} & \frac{1}{\sqrt{2}} \\ -\frac{4}{\sqrt{41}} & \frac{1}{\sqrt{2}}\end{bmatrix}
$$

We can obtain a diagonal matrix **D** such that,

$$
\mathbf{D} = \mathbf{P}^{-1}\mathbf{A}\mathbf{P}
$$

```{r}
# Create A and P
A = matrix(c(-3, 4, 5, -2), nrow = 2)
P = matrix(c(5/sqrt(41), -4/sqrt(41), 1/sqrt(2), 1/sqrt(2)), nrow = 2)

# Compute D
solve(P) %*% A %*% P
```

Note that **D** is a diagonal matrix with the two eigenvalues on the main diagonal. Namely,

$$
\mathbf{D} = \begin{bmatrix}-7 & 0\\0 & 2\end{bmatrix}
$$

Recall that we said matrix **A** was a diagonalizable matrix, which essentially boils down to the fact that we can find a matrix **P** (that is invertible) and a diagonal matrix **D** such that


$$
\mathbf{A} = \mathbf{P}\mathbf{D}\mathbf{P}^{-1}
$$

We find that **P** is a matrix composed of eigenvectors, and **D** is a diagonal matrix of eigenvalues. This is sometimes called the *eigenstructure* of matrix **A**. 


# Using R to find the Eigenstructure of a Matrix

We can use the `eigen()` function to compute the eigenvalues and eigenvectors for a diagonalizable matrix.

```{r}
# Compute eigenstructure
eigen_decomp = eigen(A)

# View output
eigen_decomp
```


We can compute on this output by coercing each list element into a matrix.

```{r}
# Create P
P = matrix(eigen_decomp$vectors, nrow = 2)

# View P
P

# Create D
D = diag(eigen_decomp$values)

# View D
D

# Compute A
P %*% D %*% solve(P)
```


